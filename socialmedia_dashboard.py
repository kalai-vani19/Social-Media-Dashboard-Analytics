# -*- coding: utf-8 -*-
"""Socialmedia dashboard.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VCPyWAE9MLuJe4K9Nhkjz8x3IZUDxjls
"""

# -------------------------------------------------------------
# INSTALL yt-dlp
# -------------------------------------------------------------
!pip install yt-dlp --quiet

from yt_dlp import YoutubeDL
import pandas as pd
import re

# -------------------------------------------------------------
# FUNCTION TO CLEAN YOUTUBE HANDLE / URL
# -------------------------------------------------------------
def extract_channel_handle(channel_input):
    """
    Accepts:
    - @handle
    - Channel URL
    - YouTube link
    Returns clean handle without '@'
    """
    if "@" in channel_input:
        return channel_input.replace("@", "").strip()
    elif "youtube.com" in channel_input:
        match = re.search(r"@([A-Za-z0-9_]+)", channel_input)
        if match:
            return match.group(1)
    return channel_input  # Use as-is


# -------------------------------------------------------------
# MAIN SCRAPER (NO API)
# Extracts Shorts + Videos + Metadata
# -------------------------------------------------------------
def scrape_youtube_channel(channel_input):
    handle = extract_channel_handle(channel_input)
    base_urls = [
        f"https://www.youtube.com/@{handle}/videos",
        f"https://www.youtube.com/@{handle}/shorts"
    ]

    all_videos = []

    ydl_opts = {
        "extract_flat": False,
        "quiet": True,
        "skip_download": True,
        "ignoreerrors": True,
    }

    with YoutubeDL(ydl_opts) as ydl:
        for url in base_urls:
            print(f"Extracting: {url}")
            data = ydl.extract_info(url, download=False)

            if not data:
                continue

            entries = data.get("entries", [])
            if not entries:
                continue

            for v in entries:
                if not isinstance(v, dict):
                    continue

                all_videos.append({
                    "title": v.get("title"),
                    "video_id": v.get("id"),
                    "url": f"https://www.youtube.com/watch?v={v.get('id')}",
                    "duration": v.get("duration"),
                    "view_count": v.get("view_count"),
                    "upload_date": v.get("upload_date"),
                    "like_count": v.get("like_count"),
                    "comment_count": v.get("comment_count")
                })

    df = pd.DataFrame(all_videos)
    df.drop_duplicates(subset="video_id", inplace=True)

    return df


# -------------------------------------------------------------
# RUN THE SCRAPER
# -------------------------------------------------------------
channel = "vibewithvarshuu"   # ‚Üê change this to any channel
df = scrape_youtube_channel(channel)

print("Total videos found:", len(df))
df.head(20)

# -------------------------------------------------------------
# SAVE TO CSV
# -------------------------------------------------------------
output_csv = "youtube_data.csv"
df.to_csv(output_csv, index=False)

# -------------------------------------------------------------
# DOWNLOAD CSV FROM COLAB
# -------------------------------------------------------------
from google.colab import files
files.download(output_csv)